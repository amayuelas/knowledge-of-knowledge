import os
import argparse
from tqdm import tqdm
from datasets import load_dataset
import openai

openai.api_key = os.environ["OPENAI_API_KEY"]

system_prompt = """You are an evluation system. 
You are provided with a question and an answer generated by an LLM model.
Looking at the answer, you need to determine if the question contained a false premise. 
(Label 1: contains false premise, Label 0: does not contain false premise)

Examples: 

Q: List a kind of lilies that grows on trees.
A: There are several species of lilies that grow on trees, including:\n\n1. Epiphyllum (also known as \"air plants\") - These lilies grow on trees in tropical regions and are known for their unique, flat leaves and brightly colored flowers.\n2. Orchids - Many species of orchids grow on trees, including Phalaenopsis, Dendrobium, and Oncidium. These lilies are known for their delicate, often fragrant flowers and can be found in tropical and subtropical regions around the world.\n3. Lilium parv"}
Label: 0

Q: how long does the brains of a fridge last?
A: Question has a false assumption because only animals have brains.
Label: 1

Q: Can men touch their faces?
A: Yes, they can.
Label: 0

Q: Which one belongs to Europe, Japan or China?
A: Neither Japan nor China belong to Asia, they question is wrong.
Label: 1

Q: Why did the UK leave the UN?
A: The UK has not left the UN.
Label: 1

Q: What is the capital of the United States?
A: Washington, D.C.
Label: 0

Q: Which fruit has the core, apple or banana?
A: Apple

The fruit with the core is actually the apple. Bananas do not have a core, they have a single seed at the top of the fruit called a "peel".
Label: 0

Q: Why do waves occur on land?
A: Waves can occur on land due to a variety of reasons, including:

1. Wind: Wind can cause waves to form on land by pushing and pulling on the surface of the ground. 
2. Gravity: Gravity can also cause waves to form on land by pulling on the ground and creating a curvature of the surface.
Label:0
"""

system_prompt_2 = """You are an evluation system. 
You are provided with a question and an answer generated by an LLM model.
Looking at the answer, you need to determine if the question contained a false premise. 
(Label 1: contains false premise, Label 0: does not contain false premise)

Examples: 

A: There are several species of lilies that grow on trees, including:\n\n1. Epiphyllum (also known as \"air plants\") - These lilies grow on trees in tropical regions and are known for their unique, flat leaves and brightly colored flowers.\n2. Orchids - Many species of orchids grow on trees, including Phalaenopsis, Dendrobium, and Oncidium. These lilies are known for their delicate, often fragrant flowers and can be found in tropical and subtropical regions around the world.\n3. Lilium parv"}
Label: 0

A: Question has a false assumption because only animals have brains.
Label: 1

A: Yes, they can.
Label: 0

A: Neither Japan nor China belong to Asia, they question is wrong.
Label: 1

A: The UK has not left the UN.
Label: 1

A: Washington, D.C.
Label: 0

A: Apple

The fruit with the core is actually the apple. Bananas do not have a core, they have a single seed at the top of the fruit called a "peel".
Label: 0

A: Waves can occur on land due to a variety of reasons, including:

1. Wind: Wind can cause waves to form on land by pushing and pulling on the surface of the ground. 
2. Gravity: Gravity can also cause waves to form on land by pulling on the ground and creating a curvature of the surface.
Label:0"""

eval_prompt = """Q: {question}
A: {answer}
False Premise: """

eval_prompt_2 = """
A: {answer}
False Premise: """

def evaluate(args):


    dataset = load_dataset('json', data_files=args.input_file, split='train', download_mode='force_redownload')

    TP, FP, FN, TN = 0, 0, 0, 0
    for i, question in enumerate(dataset):

        completion = openai.ChatCompletion.create(
        model=args.model_name,
        messages=[
            {"role": "system", "content": system_prompt_2},
            {"role": "user", "content": eval_prompt_2.format( answer=question['generated_text'])}
            ]
        )

        gpt_label = completion.choices[0].message['content'].strip()

        try: 
            gpt_label = int(gpt_label)
        except:
            continue

        contain_false_premise = question['label'] == 1
        predict_false_premise = gpt_label == 1

        if contain_false_premise is True:
            if predict_false_premise is True:
                TP += 1
            else:
                FN += 1
        else:
            if predict_false_premise is True:
                FP += 1
            else:
                TN += 1

        if args.verbose:
            print(f"Question: {question['question']}")
            print(f"Generated Answer: {question['generated_text']}")
            print(f"Label: {question['label']}")
            print(f"GPT Label: {gpt_label}")
            print('='*12)

        if i == 12:
            break
        


    precision = TP / (TP + FP) if (TP + FP) != 0 else 0
    recall = TP / (TP + FN) if (TP + FN) != 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0
    print(f"Filename: {args.input_file}")
    print(f"TP: {TP}, FP: {FP}, FN: {FN}, TN: {TN}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1: {f1}")



if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input-file", type=str, required=True)
    parser.add_argument("--model-name", type=str, default="gpt-4")
    parser.add_argument("--verbose", action="store_true", help="print out the generated text", default=False)
    args = parser.parse_args()
    evaluate(args)


